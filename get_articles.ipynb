{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f51404-6ab6-41f7-9cd3-aa8e0cb158ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import datetime\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0746e56a-1e7b-4aaf-8751-0843323350ad",
   "metadata": {},
   "source": [
    "end = datetime.date.today()\n",
    "start = end - relativedelta(years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1686761-4a83-464e-9592-63052410bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.date(2020,12,31)\n",
    "start = end - relativedelta(years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0006c70-4be9-4266-bdd2-30816b573203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020 01',\n",
       " '2020 02',\n",
       " '2020 03',\n",
       " '2020 04',\n",
       " '2020 05',\n",
       " '2020 06',\n",
       " '2020 07',\n",
       " '2020 08',\n",
       " '2020 09',\n",
       " '2020 10',\n",
       " '2020 11',\n",
       " '2020 12']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start, end, freq='MS').strftime(\"%Y %m\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179f759a-417c-4a52-831a-7e8f44875e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "months_in_range = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %#m\").tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51cc4d7c-ec97-4376-8dd7-794d36d086de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2020', '1'],\n",
       " ['2020', '2'],\n",
       " ['2020', '3'],\n",
       " ['2020', '4'],\n",
       " ['2020', '5'],\n",
       " ['2020', '6'],\n",
       " ['2020', '7'],\n",
       " ['2020', '8'],\n",
       " ['2020', '9'],\n",
       " ['2020', '10'],\n",
       " ['2020', '11'],\n",
       " ['2020', '12']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ef4726e-ec0f-412c-93be-931a06c94618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(date):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + 'IXgpV4G3MtKtTgzm7L54bXITJ2egifLm'\n",
    "    response = requests.get(url).json()\n",
    "    time.sleep(6)\n",
    "    return response\n",
    "\n",
    "\n",
    "def is_valid(article, date):\n",
    "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
    "    is_in_range = date > start and date < end\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
    "    return is_in_range and has_headline\n",
    "\n",
    "\n",
    "def parse_response(response):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "        'doc_type': [],\n",
    "        'type_of_material': [],\n",
    "        'snippet': [],\n",
    "        'source': [],\n",
    "        'news_desk': [],\n",
    "        'section_name': [],\n",
    "        'keywords': []}\n",
    "    \n",
    "    articles = response['response']['docs']\n",
    "    optional_features = ['section_name', 'type_of_material', 'snippet', 'source', 'news_desk']\n",
    "\n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "        if is_valid(article, date):\n",
    "            data['date'].append(date)\n",
    "            data['headline'].append(article['headline']['main'])\n",
    "            data['doc_type'].append(article['document_type'])\n",
    "            data['keywords'].append(keywords)\n",
    "            for feature in optional_features:\n",
    "                if feature in article:\n",
    "                    data[feature].append(article[feature])\n",
    "                else:\n",
    "                    data[feature].append(None)\n",
    "            \n",
    "    return pd.DataFrame(data) \n",
    "\n",
    "excluded_sections = ['Style','The Learning Network', 'Arts', \n",
    "                     'Opinion', 'Books', 'Corrections','Food',\n",
    "                     'T Magazine', 'Times Insider', 'Magazine',\n",
    "                     'The Upshot', 'Crosswords & Games', 'Reader Center',\n",
    "                     'Fashion & Style', 'Podcasts', 'Sports', 'Theater', \n",
    "                     'Parenting','Movies']\n",
    "\n",
    "excluded_news = ['Podcasts', 'Summary']\n",
    "\n",
    "def get_data(dates):\n",
    "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
    "    total = 0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'):\n",
    "        os.mkdir('headlines')\n",
    "    for date in dates:\n",
    "        response = send_request(date)\n",
    "        df = parse_response(response)\n",
    "        df_sorted = df[(df['doc_type'] == 'article') & (df['type_of_material'] == 'News')]\n",
    "        df_sorted = df_sorted[~df_sorted['section_name'].isin(excluded_sections)]\n",
    "        df_sorted = df_sorted[~df_sorted['news_desk'].isin(excluded_news)]\n",
    "        total += len(df_sorted)\n",
    "        df_sorted.to_csv('headlines/' + date[0] + '-' + date[1] + '.csv', index=False)\n",
    "        print('Saving headlines/' + date[0] + '-' + date[1] + '.csv...')\n",
    "    print('Number of articles collected: ' + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e62db3f5-6471-4064-942d-ee6cb5087cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: ['2020', '1'] to ['2020', '12']\n",
      "Saving headlines/2020-1.csv...\n",
      "Saving headlines/2020-2.csv...\n",
      "Saving headlines/2020-3.csv...\n",
      "Saving headlines/2020-4.csv...\n",
      "Saving headlines/2020-5.csv...\n",
      "Saving headlines/2020-6.csv...\n",
      "Saving headlines/2020-7.csv...\n",
      "Saving headlines/2020-8.csv...\n",
      "Saving headlines/2020-9.csv...\n",
      "Saving headlines/2020-10.csv...\n",
      "Saving headlines/2020-11.csv...\n",
      "Saving headlines/2020-12.csv...\n",
      "Number of articles collected: 24864\n"
     ]
    }
   ],
   "source": [
    "get_data(months_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cecd14-65c2-4b8d-9c91-81d7dc122451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
